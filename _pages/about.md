---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# Biography

Hi! I am **Jiazhe Wei (È≠è‰Ω≥Âì≤)**, an <u>incoming master student</u> majoring in Intelligent Science and Technology at Nanjing University and doing research at [Pattern Recognition Lab](https://prlab-nju.com/nju/) @NJU, supervised by Prof. [Chenyang Si](https://scholar.google.com/citations?hl=en&user=XdahAuoAAAAJ) and Prof. [Tieniu Tan](https://scholar.google.com/citations?user=W-FGd_UAAAAJ&hl=en).

My research interests mainly focus on: **1) Highly Controllable Visual Generative Models; 2) World Foundation Models; 3) Efficient Generative Models and Model Compression; 4) Unified Multi-modal Learning**. 

‚ú® <i style="color: red;">I'm always open to all kinds of cooperation and discussion.</i> **You can contact me via email or WeChat: wjz_void.**



# üìù Publications | [Google Scholar](https://scholar.google.com/citations?user=UgKRQJwAAAAJ&hl=en&oi=ao)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Arxiv</div><img src='images/teaser.png' alt="PosterCopilot" style="width: 100%; height: auto; object-fit: cover; max-height: 280px;"></div></div>

<div class='paper-box-text' markdown="1">

[PosterCopilot: Toward Layout Reasoning and Controllable Editing for Professional Graphic Design](https://arxiv.org/pdf/2512.04082)

**Jiazhe Wei** *, Ken Li *, Tianyu Lao, Haofan Wang, Liang Wang, Caifeng Shan, Chenyang Si

[**[PDF]**](https://arxiv.org/pdf/2512.04082)  [**[Project Page]**](https://postercopilot.github.io/) [**[Github]**](https://github.com/JiazheWei/PosterCopilot)  <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

**TL;DR:** *We introduce PosterCopilot, the first graphic design framework that fully integrates visual feedback with human aesthetics. Leveraging our Generative Agent and the design model's powerful reasoning capabilities, it enables layer-level, multi-round, high-fidelity editing.*

</div>

</div>
---

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECML-PKDD 2025 Oral</div><img src='images/ALM-PU.png' alt="ALM-PU" style="width: 100%; height: auto; object-fit: cover; max-height: 200px;"></div></div>

<div class='paper-box-text' markdown="1">

[ALM-PU: Positive and Unlabeled learning with constrained optimization](https://link.springer.com/article/10.1007/s10994-025-06849-3)

**Jiazhe Wei**<sup style="font-size: 1.1em; position: relative; top: -2px;">*</sup>, Yuefei Wu<sup style="font-size: 1.1em; position: relative; top: -2px;">*</sup>, Ken Li, Bo Dong, Bin Shi<sup>‚Ä†</sup>

[**[PDF]**](https://link.springer.com/article/10.1007/s10994-025-06849-3) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>    [**[Github]**](https://github.com/xjtu-wjz/ALM-PU-Positive-and-Unlabeled-Learning-with-Constrained-Optimization) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

**TL;DR:** *We propose a novel constraint optimization-based PU-learning framework, which enhances sample discrimination capability by imposing distinct mathematical constraints on samples and resolving the problem through systematic optimization.*

</div>

</div>

---

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">WWW 2025 Oral</div><img src='images/backdoor.png' alt="NI-GDBA" style="width: 100%; height: auto; object-fit: cover; max-height: 200px;"></div></div>

<div class='paper-box-text' markdown="1">

[NI-GDBA: Non-Intrusive Distributed Backdoor Attack Based on Adaptive Perturbation on Federated Graph Learning](https://openreview.net/pdf?id=yexIJEru0l)

Ken Li, Bin Shi, **Jiazhe Wei**, Bo Dong

[**[PDF]**](https://openreview.net/pdf?id=yexIJEru0l) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

**TL;DR:** *We propose a non-intrusive graph distributed backdoor attack(NI-GDBA) that does not require backdoor triggers to be injected in the training data.*

</div>

</div>

---

<i>\* Equal contribution. ‚Ä† Corresponding author.</i>

# üî¨ Research & Visiting Experience

<div style="display: flex; align-items: center; margin-bottom: 20px;">
  <img src="images/Lovart-logo.png" alt="lovart" style="width: 120px; height: 120px; margin-right: 20px; object-fit: contain; flex-shrink: 0;">
  <div>
    <p style="margin: 0;"><strong><a href="http://opengvlab.shlab.org.cn/">LinsLab</a>, Learning and Inference Systems Lab, Westlake University & Zhejiang University</strong></p>
    <p style="margin: 5px 0; font-size: 14px;"><em>2024.11 - Present, Intern Researcher, Hangzhou, China</em></p>
    <p style="margin: 5px 0; font-size: 14px;">Working with <a href="https://www.westlake.edu.cn/faculty/tao-lin.html">Prof. Tao Lin</a> and <a href="https://sp12138.github.io/">Dr. Peng Sun</a></p>
  </div>
</div>
---
<div style="display: flex; align-items: center; margin-bottom: 20px;">
  <img src="images/linslab.png" alt="LinsLab" style="width: 120px; height: 120px; margin-right: 20px; object-fit: contain; flex-shrink: 0;">
  <div>
    <p style="margin: 0;"><strong><a href="https://lins-lab.github.io/">LinsLab</a>, Learning and Inference Systems Lab, Westlake University & Zhejiang University</strong></p>
    <p style="margin: 5px 0; font-size: 14px;"><em>2024.11 - Present, Intern Researcher, Hangzhou, China</em></p>
    <p style="margin: 5px 0; font-size: 14px;">Working with <a href="https://www.westlake.edu.cn/faculty/tao-lin.html">Prof. Tao Lin</a> and <a href="https://sp12138.github.io/">Dr. Peng Sun</a></p>
  </div>
</div>

---
<div style="display: flex; align-items: center; margin-bottom: 20px;">
  <img src="images/CERN.jpg" alt="CERN" style="width: 120px; height: 120px; margin-right: 20px; object-fit: contain; flex-shrink: 0;">
  <div>
    <p style="margin: 0;"><strong>European Organization for Nuclear Research & CERN</strong></p>
    <p style="margin: 5px 0; font-size: 14px;"><em>2025.01 - 2025.02, Visiting Student, Geneva, Switzerland</em></p>
    <p style="margin: 5px 0; font-size: 14px;">Supervised by <a href="https://inspirehep.net/authors/1071677">Prof. Zhili Weng</a></p>
  </div>
</div>

---
<div style="display: flex; align-items: center; margin-bottom: 20px;">
  <img src="images/xjtu.png" alt="BDKElab" style="width: 120px; height: 120px; margin-right: 20px; object-fit: contain; flex-shrink: 0;">
  <div>
    <p style="margin: 0;"><strong><a href="https://bdkelab.xjtu.edu.cn/sysjj/sysjj.htm">BDKElab</a>, Xi'an Jiaotong University</strong></p>
    <p style="margin: 5px 0; font-size: 14px;"><em>2023.09 - 2024.10, Research Assistant, Xi'an, China</em></p>
    <p style="margin: 5px 0; font-size: 14px;">This was a period filled with bitterness and twists and turns -- a detour I had to take in my research career. Despite this, I remain grateful for the experience, as it taught me early on what kind of taste an independent researcher should cultivate, what abilities they must possess, and the importance of reaching outward to embrace the whole world.</p>
  </div>
</div>


# üéñ Honors and Awards (Selected)

<!-- ÈúÄË¶ÅÂõæÁâá: files/photo/highlight/lanqiao.jpg -->
<!-- ÈúÄË¶ÅÂõæÁâá: files/photo/highlight/baogang.png -->

- *2024* **Baosteel Outstanding Student Scholarship (ÂÆùÈí¢‰ºòÁßÄÂ≠¶ÁîüÂ•ñÂ≠¶Èáë)**, Awarded to 400 top Chinese undergraduates nationwide
- *2024* **350 points, ranked in top 2% nationwide**, CCF Certified Software Professional(CSP)
- *2024* **National Third Prize** ü•â, Blue Bridge Cup National Software and Information Technology Professionals Competition (Á¨¨ÂçÅ‰∫îÂ±äËìùÊ°•ÊùØÁ®ãÂ∫èËÆæËÆ°Â§ßËµõC++AÁªÑ--ÂÖ®ÂõΩÊÄªÂÜ≥Ëµõ)
- *2023* **Gold Medal** ü•á, Bai Du--A star Programming Competition
- *2023* First scholarship for Outstanding Students
- *2023, 2024* Dean's list
- *2023* **Silver Medal**, (CCPC) China Collegiate Programming Contest National Invitational Contest
- *2023* HuaWei scholarship
- *2023* National third prize, Chinese College Students English Academic Proficiency Competition

# üìñ Education

<div style="display: flex; align-items: center; margin-bottom: 20px;">
  <img src="images/xjtu.png" alt="XJTU" style="width: 115px; height: 115px; margin-right: 20px; object-fit: contain; flex-shrink: 0;">
  <div>
    <p style="margin: 0;"><strong>Xi'an Jiaotong University (XJTU)</strong>, China</p>
    <p style="margin: 5px 0; font-size: 14px;"><em>2022.09 - 2026.06 (expected)</em></p>
    <p style="margin: 5px 0; font-size: 14px;"><strong>B.Eng. in Computer Science and Technology (<a href="http://www.cs.xjtu.edu.cn/info/2384/2460.htm">Qian Xuesen Honor Class</a>)</strong></p>
    <p style="margin: 5px 0; font-size: 14px;">‚Ä¢ GPA: 91.97 / 100</p>
    <p style="margin: 5px 0; font-size: 14px;">‚Ä¢ Ranking: 3/43</p>
  </div>
</div>


# üíª Engineering Experience

<!-- ÈúÄË¶ÅÂõæÁâá: files/work/Paranormal-XJTU.png -->

**Paranormal-XJTU: A 2D game developed by Unity**

*May, 2024, Project Leader & 6-people Team*

As an ordinary college student, one day you suddenly found that your school began to circulate a variety of ghosts and monsters. At the same time, your classmates also behaved abnormally one after another, and you, how will you solve the mystery?

[[Play](https://github.com/Team-Ferry/Paranormal-XJTU?tab=readme-ov-file)]

# üëî Leadership Experience

- *2023.04 - present*, **Captain**, [XJTU deep learning seminar](https://xjtu-deeplearning-seminar.github.io/dl-discussion/)
- *2024.07 - present*, **Captain of the Computer Experimental Class**

# üìã Academic Services

**Reviewer**: AAAI 2025, ECML-PKDD 2025

---

<p style="text-align: center; font-size: small;"><i>Latest updated in Dec. 2025</i></p>
<p style="text-align: center;">¬© Jiazhe Wei</p>